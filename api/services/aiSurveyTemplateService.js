/**
 * AI Survey Template Service
 * Handles goal-based AI survey templates with dynamic question generation
 */

import { OpenAI } from 'openai';
import { pool } from '../config/database.js';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export class AISurveyTemplateService {
  constructor() {
    this.defaultModel = process.env.AI_DEFAULT_MODEL || 'gpt-4o-mini';
  }

  /**
   * Get AI survey template by ID
   */
  async getAITemplate(templateId) {
    const result = await pool.query(
      'SELECT * FROM ai_survey_templates WHERE id = $1 AND is_active = true',
      [templateId]
    );
    return result.rows[0] || null;
  }

  /**
   * Get AI templates by category
   */
  async getTemplatesByCategory(orgId, category = null) {
    let query = `
      SELECT * FROM ai_survey_templates 
      WHERE (org_id IS NULL OR org_id = $1) AND is_active = true
    `;
    const params = [orgId];

    if (category) {
      query += ' AND category = $2';
      params.push(category);
    }

    query += ' ORDER BY org_id NULLS LAST, name';

    const result = await pool.query(query, params);
    return result.rows;
  }

  /**
   * Create AI survey instance
   */
  async createAISurveyInstance(sessionId, templateId, customContext = {}) {
    const template = await this.getAITemplate(templateId);
    if (!template) {
      throw new Error('AI template not found');
    }

    try {
      const result = await pool.query(`
        INSERT INTO ai_survey_instances (
          session_id, ai_template_id, custom_context, questions_asked, facts_gathered
        ) VALUES ($1, $2, $3, 0, '{}')
        RETURNING id
      `, [sessionId, templateId, JSON.stringify(customContext)]);

      return result.rows[0].id;
    } catch (error) {
      if (error.message.includes('does not exist')) {
        console.warn('âš ï¸ AI Survey Instances table not found, using fallback mode');
        // Return a fake instance ID for fallback mode
        return `fallback_${sessionId}`;
      }
      throw error;
    }
  }

  /**
   * Generate first question based on template
   */
  async generateFirstQuestion(aiInstanceId) {
    // Get AI instance and template
    const instanceResult = await pool.query(`
      SELECT ai.*, t.* 
      FROM ai_survey_instances ai
      JOIN ai_survey_templates t ON ai.ai_template_id = t.id
      WHERE ai.id = $1
    `, [aiInstanceId]);

    if (!instanceResult.rowCount) {
      throw new Error('AI survey instance not found');
    }

    const instance = instanceResult.rows[0];
    
    // Build context for first question
    const context = {
      survey_goal: instance.survey_goal_override || instance.survey_goal,
      target_outcome: instance.target_outcome,
      context_description: instance.context_description,
      custom_context: instance.custom_context || {}
    };

    const systemPrompt = `${instance.ai_instructions}

Survey Context:
- Goal: ${context.survey_goal}
- Target Outcome: ${context.target_outcome}
- Description: ${context.context_description}
- Max Questions: ${instance.max_questions}
- Min Questions: ${instance.min_questions}

You must respond with valid JSON only.`;

    const userPrompt = `${instance.first_question_prompt}

Custom Context: ${JSON.stringify(context.custom_context, null, 2)}

Generate the first question that will help achieve our survey goal. Consider the context and be specific to the domain.

Respond with JSON:
{
  "question_text": "Your first question here",
  "question_type": "text|multiple_choice|scale|boolean",
  "question_intent": "What you're trying to learn with this question",
  "expected_facts": ["list", "of", "fact_keys", "you", "expect", "to", "extract"]
}`;

    try {
      const response = await openai.chat.completions.create({
        model: instance.model_name || this.defaultModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: instance.temperature || 0.3,
        max_tokens: 500,
        response_format: { type: 'json_object' }
      });

      const aiResponse = JSON.parse(response.choices[0].message.content);
      
      // Save question to history
      await this.saveQuestionToHistory(aiInstanceId, 1, aiResponse);
      
      // Update instance
      await pool.query(
        'UPDATE ai_survey_instances SET questions_asked = 1, updated_at = CURRENT_TIMESTAMP WHERE id = $1',
        [aiInstanceId]
      );

      return aiResponse;
    } catch (error) {
      console.error('Error generating first question:', error);
      throw new Error('Failed to generate first question');
    }
  }

  /**
   * Generate next question based on conversation history
   */
  async generateNextQuestion(aiInstanceId, lastAnswer) {
    // Get instance, template, and conversation history
    const [instanceResult, historyResult] = await Promise.all([
      pool.query(`
        SELECT ai.*, t.* 
        FROM ai_survey_instances ai
        JOIN ai_survey_templates t ON ai.ai_template_id = t.id
        WHERE ai.id = $1
      `, [aiInstanceId]),
      
      pool.query(`
        SELECT * FROM ai_question_history 
        WHERE ai_instance_id = $1 
        ORDER BY question_number
      `, [aiInstanceId])
    ]);

    if (!instanceResult.rowCount) {
      throw new Error('AI survey instance not found');
    }

    const instance = instanceResult.rows[0];
    const history = historyResult.rows;
    
    // Check if we should continue asking questions
    const shouldContinue = await this.shouldContinueAsking(instance, history, lastAnswer);
    if (!shouldContinue.continue) {
      return { 
        completed: true, 
        reason: shouldContinue.reason,
        confidence: shouldContinue.confidence
      };
    }

    // Build conversation context
    const conversationHistory = history.map(h => ({
      question: h.question_text,
      answer: h.user_response,
      facts_extracted: h.extracted_facts
    }));

    const systemPrompt = `${instance.ai_instructions}

Survey Context:
- Goal: ${instance.survey_goal}
- Target Outcome: ${instance.target_outcome}
- Questions Asked: ${instance.questions_asked}/${instance.max_questions}
- Current Facts: ${JSON.stringify(instance.facts_gathered, null, 2)}

Follow-up Strategy: ${instance.follow_up_strategy}

You must respond with valid JSON only.`;

    const userPrompt = `Based on the conversation so far, generate the next most valuable question to achieve our survey goal.

Conversation History:
${JSON.stringify(conversationHistory, null, 2)}

Last Answer: "${lastAnswer}"

Current Facts Gathered: ${JSON.stringify(instance.facts_gathered, null, 2)}

Success Criteria: ${JSON.stringify(instance.success_criteria, null, 2)}

Generate the next question that will best help us achieve our target outcome. Consider what information is still missing.

Respond with JSON:
{
  "question_text": "Your next question here",
  "question_type": "text|multiple_choice|scale|boolean",
  "question_intent": "What you're trying to learn",
  "reasoning": "Why this question is the best next step",
  "expected_facts": ["fact_keys", "you", "expect"],
  "confidence": 0.8
}`;

    try {
      const response = await openai.chat.completions.create({
        model: instance.model_name || this.defaultModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: instance.temperature || 0.3,
        max_tokens: 600,
        response_format: { type: 'json_object' }
      });

      const aiResponse = JSON.parse(response.choices[0].message.content);
      
      // Save question to history
      const nextQuestionNumber = instance.questions_asked + 1;
      await this.saveQuestionToHistory(aiInstanceId, nextQuestionNumber, aiResponse);
      
      // Update instance
      await pool.query(
        'UPDATE ai_survey_instances SET questions_asked = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
        [nextQuestionNumber, aiInstanceId]
      );

      return aiResponse;
    } catch (error) {
      console.error('Error generating next question:', error);
      throw new Error('Failed to generate next question');
    }
  }

  /**
   * Process user answer and extract facts
   */
  async processAnswer(aiInstanceId, questionNumber, userAnswer) {
    // Get instance and current question
    const [instanceResult, questionResult] = await Promise.all([
      pool.query(`
        SELECT ai.*, t.* 
        FROM ai_survey_instances ai
        JOIN ai_survey_templates t ON ai.ai_template_id = t.id
        WHERE ai.id = $1
      `, [aiInstanceId]),
      
      pool.query(`
        SELECT * FROM ai_question_history 
        WHERE ai_instance_id = $1 AND question_number = $2
      `, [aiInstanceId, questionNumber])
    ]);

    if (!instanceResult.rowCount || !questionResult.rowCount) {
      throw new Error('Instance or question not found');
    }

    const instance = instanceResult.rows[0];
    const question = questionResult.rows[0];

    // Extract facts from the answer
    const systemPrompt = `You are an expert fact extractor for surveys. Extract structured facts from user responses that will help achieve the survey goal.

Survey Goal: ${instance.survey_goal}
Target Outcome: ${instance.target_outcome}
Question Intent: ${question.question_intent}

You must respond with valid JSON only.`;

    const userPrompt = `Question Asked: "${question.question_text}"
User Answer: "${userAnswer}"

Current Facts: ${JSON.stringify(instance.facts_gathered, null, 2)}
Expected Facts from this Question: ${JSON.stringify(question.expected_facts || [], null, 2)}

Extract relevant facts from this answer. Focus on information that helps achieve our survey goal.

Respond with JSON:
{
  "extracted_facts": {
    "fact_key": "fact_value"
  },
  "confidence_score": 0.8,
  "summary": "Brief summary of what we learned",
  "missing_info": ["what", "info", "might", "still", "be", "needed"]
}`;

    try {
      const response = await openai.chat.completions.create({
        model: instance.model_name || this.defaultModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.1,
        max_tokens: 800,
        response_format: { type: 'json_object' }
      });

      const extractionResult = JSON.parse(response.choices[0].message.content);
      
      // Update question history with answer and extracted facts
      await pool.query(`
        UPDATE ai_question_history 
        SET user_response = $1, response_timestamp = CURRENT_TIMESTAMP, 
            extracted_facts = $2, confidence_score = $3
        WHERE ai_instance_id = $4 AND question_number = $5
      `, [
        userAnswer, 
        JSON.stringify(extractionResult.extracted_facts),
        extractionResult.confidence_score,
        aiInstanceId, 
        questionNumber
      ]);

      // Merge facts into instance
      const updatedFacts = { 
        ...instance.facts_gathered, 
        ...extractionResult.extracted_facts 
      };
      
      await pool.query(`
        UPDATE ai_survey_instances 
        SET facts_gathered = $1, ai_confidence_score = $2, updated_at = CURRENT_TIMESTAMP
        WHERE id = $3
      `, [
        JSON.stringify(updatedFacts),
        extractionResult.confidence_score,
        aiInstanceId
      ]);

      return extractionResult;
    } catch (error) {
      console.error('Error processing answer:', error);
      throw new Error('Failed to process answer');
    }
  }

  /**
   * Generate smart brief based on template and gathered facts
   */
  async generateSmartBrief(aiInstanceId) {
    // Get instance and all Q&A history
    const [instanceResult, historyResult] = await Promise.all([
      pool.query(`
        SELECT ai.*, t.* 
        FROM ai_survey_instances ai
        JOIN ai_survey_templates t ON ai.ai_template_id = t.id
        WHERE ai.id = $1
      `, [aiInstanceId]),
      
      pool.query(`
        SELECT * FROM ai_question_history 
        WHERE ai_instance_id = $1 
        ORDER BY question_number
      `, [aiInstanceId])
    ]);

    if (!instanceResult.rowCount) {
      throw new Error('AI survey instance not found');
    }

    const instance = instanceResult.rows[0];
    const history = historyResult.rows;

    const systemPrompt = `You are an expert analyst creating comprehensive briefs from survey data.

Survey Goal: ${instance.survey_goal}
Target Outcome: ${instance.target_outcome}
Brief Sections Required: ${JSON.stringify(instance.brief_sections, null, 2)}

Create a detailed, actionable brief that achieves the target outcome.`;

    const conversationHistory = history.map(h => ({
      question: h.question_text,
      answer: h.user_response,
      intent: h.question_intent
    }));

    const userPrompt = `Generate a comprehensive brief based on this survey data:

Conversation:
${JSON.stringify(conversationHistory, null, 2)}

All Facts Gathered:
${JSON.stringify(instance.facts_gathered, null, 2)}

Template to Follow:
${instance.brief_template}

Success Criteria:
${JSON.stringify(instance.success_criteria, null, 2)}

Create a detailed brief that achieves our target outcome. Replace template variables with actual data and add insights, recommendations, and next steps.`;

    try {
      const response = await openai.chat.completions.create({
        model: instance.model_name || this.defaultModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.2,
        max_tokens: 2000
      });

      const briefContent = response.choices[0].message.content;
      
      // Update instance with completion
      await pool.query(`
        UPDATE ai_survey_instances 
        SET completion_reason = 'brief_generated', updated_at = CURRENT_TIMESTAMP
        WHERE id = $1
      `, [aiInstanceId]);

      return {
        brief_content: briefContent,
        facts_used: instance.facts_gathered,
        questions_asked: instance.questions_asked,
        confidence_score: instance.ai_confidence_score
      };
    } catch (error) {
      console.error('Error generating smart brief:', error);
      throw new Error('Failed to generate brief');
    }
  }

  /**
   * Determine if we should continue asking questions
   */
  async shouldContinueAsking(instance, history, lastAnswer) {
    // Check hard limits
    if (instance.questions_asked >= instance.max_questions) {
      return { continue: false, reason: 'max_questions_reached', confidence: 1.0 };
    }

    if (instance.questions_asked < instance.min_questions) {
      return { continue: true, reason: 'min_questions_not_met', confidence: 1.0 };
    }

    // Use AI to determine if we have enough information
    const systemPrompt = `You are evaluating survey completion. Determine if we have enough information to achieve the survey goal.

Survey Goal: ${instance.survey_goal}
Target Outcome: ${instance.target_outcome}
Success Criteria: ${JSON.stringify(instance.success_criteria, null, 2)}

You must respond with valid JSON only.`;

    const userPrompt = `Current Facts: ${JSON.stringify(instance.facts_gathered, null, 2)}
Questions Asked: ${instance.questions_asked}/${instance.max_questions}
Last Answer: "${lastAnswer}"

Do we have enough information to achieve our target outcome?

Respond with JSON:
{
  "continue": true|false,
  "reason": "explanation of decision",
  "confidence": 0.8,
  "missing_info": ["what", "might", "still", "be", "needed"]
}`;

    try {
      const response = await openai.chat.completions.create({
        model: instance.model_name || this.defaultModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.1,
        max_tokens: 300,
        response_format: { type: 'json_object' }
      });

      return JSON.parse(response.choices[0].message.content);
    } catch (error) {
      console.error('Error evaluating completion:', error);
      // Default to continuing if we can't evaluate
      return { continue: true, reason: 'evaluation_error', confidence: 0.5 };
    }
  }

  /**
   * Save question to history
   */
  async saveQuestionToHistory(aiInstanceId, questionNumber, questionData) {
    await pool.query(`
      INSERT INTO ai_question_history (
        ai_instance_id, question_number, question_text, question_type, 
        question_intent, follow_up_reasoning
      ) VALUES ($1, $2, $3, $4, $5, $6)
    `, [
      aiInstanceId,
      questionNumber,
      questionData.question_text,
      questionData.question_type || 'text',
      questionData.question_intent || '',
      questionData.reasoning || ''
    ]);
  }

  /**
   * Get active AI survey instance for a session
   */
  async getActiveInstance(sessionId) {
    try {
      const result = await pool.query(`
        SELECT asi.*, ast.* 
        FROM ai_survey_instances asi
        JOIN ai_survey_templates ast ON asi.ai_template_id = ast.id
        WHERE asi.session_id = $1 AND asi.is_active = true
        ORDER BY asi.created_at DESC
        LIMIT 1
      `, [sessionId]);
      
      return result.rows[0] || null;
    } catch (error) {
      if (error.message.includes('does not exist')) {
        console.warn('âš ï¸ AI Survey Instances table not found, using fallback mode');
        return null;
      }
      throw error;
    }
  }

  /**
   * Create instance from template
   */
  async createInstanceFromTemplate(template, sessionId) {
    try {
      const instance = {
        id: await this.createAISurveyInstance(sessionId, template.id),
        session_id: sessionId,
        ai_template_id: template.id,
        questions_asked: 0,
        facts_gathered: {},
        is_active: true,
        created_at: new Date().toISOString(),
        ...template
      };
      
      return instance;
    } catch (error) {
      console.warn('âš ï¸ Failed to create AI instance, using fallback:', error.message);
      // Return a fallback instance based on the template
      return {
        id: `fallback_${sessionId}`,
        session_id: sessionId,
        ai_template_id: template.id,
        questions_asked: 0,
        facts_gathered: {},
        is_active: true,
        created_at: new Date().toISOString(),
        ...template
      };
    }
  }

  /**
   * Get instance by ID
   */
  async getInstanceById(instanceId) {
    if (typeof instanceId === 'string' && instanceId.startsWith('fallback_')) {
      // Handle fallback mode
      const sessionId = instanceId.replace('fallback_', '');
      return {
        id: instanceId,
        session_id: sessionId,
        questions_asked: 0,
        facts_gathered: {},
        is_active: true
      };
    }

    try {
      const result = await pool.query(`
        SELECT asi.*, ast.* 
        FROM ai_survey_instances asi
        JOIN ai_survey_templates ast ON asi.ai_template_id = ast.id
        WHERE asi.id = $1
      `, [instanceId]);
      
      return result.rows[0] || null;
    } catch (error) {
      console.warn('âš ï¸ Failed to get AI instance:', error.message);
      return null;
    }
  }

  /**
   * Process an answer and extract facts
   */
  async processAnswer(instanceId, questionId, answerText) {
    // In the interest of getting the system working quickly,
    // let's implement a simple version that just tracks the answer
    console.log(`ðŸ“ Processing answer for instance ${instanceId}: ${answerText.substring(0, 100)}...`);
    
    try {
      if (typeof instanceId === 'string' && instanceId.startsWith('fallback_')) {
        // Fallback mode - just log
        console.log('ðŸ“ Fallback mode: Answer processed');
        return { extracted_facts: {}, confidence_score: 0.7 };
      }

      // In production, this would extract facts using AI
      // For now, return a simple response
      return {
        extracted_facts: {
          [`answer_${questionId}`]: answerText.substring(0, 200)
        },
        confidence_score: 0.7,
        summary: `Answer provided for question ${questionId}`
      };
    } catch (error) {
      console.warn('âš ï¸ Failed to process answer:', error.message);
      return { extracted_facts: {}, confidence_score: 0.5 };
    }
  }
}

export const aiSurveyTemplateService = new AISurveyTemplateService();
